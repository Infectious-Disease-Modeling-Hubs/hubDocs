# History and Motivation  

In the early 2010s there were many infectious disease forecasting models, but most were published months to years after the forecasted event. These models often had very different targets they were forecasting, such as weekly incidence, epidemic duration, monthly visits, and time of peak incidence. Additionally, the accuracy of these models were evaluated using very different metrics, such as the mean absolute error, median absolute error, and correlation. All of these factors made comparing these forecast models in a fair, consistent, and accurate way, very challenging. In a scoping review of influenza forecasting in human populations published in 2014, Chretien et al concluded that:  

```{margin}
[Chretien, J. P., George, D., Shaman, J., Chitale, R. A., & McKenzie, F. E. (2014). Influenza forecasting in human populations: a scoping review. *PloS one*, 9(4), e94130.](https://pubmed.ncbi.nlm.nih.gov/24714027/)
```
```{epigraph}
"Comparing the accuracy of forecasting applications is difficult because forecasting methods, forecast outcomes, and reported validation metrics varied widely."
```
<!--- 
Continue to add slides and images from here:
https://docs.google.com/presentation/d/1518iadkaPnFRnzblQAdnrsMbORhdTJP7Y_kW7Gu3Uyg/edit#slide=id.g25099556782_0_22
Issue #52 here:
https://github.com/Infectious-Disease-Modeling-Hubs/hubDocs/issues/52
--->

